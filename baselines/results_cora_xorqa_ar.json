[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "baselines/cora_xorqa_ar.tsv", "ARES_Prediction": 0.8992501802451334, "ARES_Confidence_Interval": [0.864, 0.934], "Number_of_Examples_in_Evaluation_Set": 1387, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.919}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "baselines/cora_xorqa_ar.tsv", "ARES_Prediction": 0.9750372506608989, "ARES_Confidence_Interval": [0.94, 1.01], "Number_of_Examples_in_Evaluation_Set": 1387, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.978}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "baselines/cora_xorqa_ar.tsv", "ARES_Prediction": 0.6938476327805816, "ARES_Confidence_Interval": [0.64, 0.748], "Number_of_Examples_in_Evaluation_Set": 1387, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.927}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "baselines/cora_xorqa_ar.tsv", "ARES_Prediction": 0.8267195385724586, "ARES_Confidence_Interval": [0.772, 0.881], "Number_of_Examples_in_Evaluation_Set": 1387, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.647}]]