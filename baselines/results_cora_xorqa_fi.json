[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "baselines/cora_xorqa_fi.tsv", "ARES_Prediction": 0.9204517453798767, "ARES_Confidence_Interval": [0.885, 0.956], "Number_of_Examples_in_Evaluation_Set": 974, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.94}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "baselines/cora_xorqa_fi.tsv", "ARES_Prediction": 0.9525188227241616, "ARES_Confidence_Interval": [0.916, 0.989], "Number_of_Examples_in_Evaluation_Set": 974, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.956}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "baselines/cora_xorqa_fi.tsv", "ARES_Prediction": 0.7255989048596851, "ARES_Confidence_Interval": [0.672, 0.779], "Number_of_Examples_in_Evaluation_Set": 974, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.959}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "baselines/cora_xorqa_fi.tsv", "ARES_Prediction": 0.8278439425051334, "ARES_Confidence_Interval": [0.771, 0.885], "Number_of_Examples_in_Evaluation_Set": 974, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.648}]]