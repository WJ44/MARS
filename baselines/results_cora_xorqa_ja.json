[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "baselines/cora_xorqa_ja.tsv", "ARES_Prediction": 0.7924098124098123, "ARES_Confidence_Interval": [0.749, 0.836], "Number_of_Examples_in_Evaluation_Set": 693, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.812}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "baselines/cora_xorqa_ja.tsv", "ARES_Prediction": 0.964920634920635, "ARES_Confidence_Interval": [0.929, 1.001], "Number_of_Examples_in_Evaluation_Set": 693, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.968}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "baselines/cora_xorqa_ja.tsv", "ARES_Prediction": 0.6151515151515152, "ARES_Confidence_Interval": [0.557, 0.674], "Number_of_Examples_in_Evaluation_Set": 693, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.848}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "baselines/cora_xorqa_ja.tsv", "ARES_Prediction": 0.9375757575757575, "ARES_Confidence_Interval": [0.88, 0.995], "Number_of_Examples_in_Evaluation_Set": 693, "Ground_Truth_Performance": null, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": null, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.758}]]