[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.4724099099099099, "ARES_Confidence_Interval": [0.425, 0.52], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.895, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.46946169772256735, "ARES_Confidence_Interval": [0.421, 0.518], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.921, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5086741016109045, "ARES_Confidence_Interval": [0.46, 0.557], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.895, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5240524781341107, "ARES_Confidence_Interval": [0.475, 0.573], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.917, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.5495267072346179, "ARES_Confidence_Interval": [0.501, 0.598], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.909, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.5808694121788103, "ARES_Confidence_Interval": [0.532, 0.63], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.5957875457875458, "ARES_Confidence_Interval": [0.547, 0.645], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.5939756746484226, "ARES_Confidence_Interval": [0.545, 0.643], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.6373767258382642, "ARES_Confidence_Interval": [0.588, 0.686], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.923, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.49284909909909913, "ARES_Confidence_Interval": [0.447, 0.538], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.927, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.5194616977225673, "ARES_Confidence_Interval": [0.474, 0.565], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.894, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5261462205700124, "ARES_Confidence_Interval": [0.48, 0.572], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.918, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5594752186588922, "ARES_Confidence_Interval": [0.513, 0.606], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.922, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.5843137254901961, "ARES_Confidence_Interval": [0.538, 0.631], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.924, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.6023583245336149, "ARES_Confidence_Interval": [0.555, 0.649], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.92, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.6336996336996337, "ARES_Confidence_Interval": [0.587, 0.681], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.92, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.6337134169517293, "ARES_Confidence_Interval": [0.586, 0.681], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.903, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.6779092702169626, "ARES_Confidence_Interval": [0.631, 0.725], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.914, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.4790202702702703, "ARES_Confidence_Interval": [0.42, 0.538], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.71, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.4995385980479148, "ARES_Confidence_Interval": [0.44, 0.559], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.718, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.49929368029739774, "ARES_Confidence_Interval": [0.44, 0.559], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.73, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5125947521865889, "ARES_Confidence_Interval": [0.453, 0.572], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.5036916835699797, "ARES_Confidence_Interval": [0.444, 0.564], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.758, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.531974656810982, "ARES_Confidence_Interval": [0.472, 0.592], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.77, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.529010989010989, "ARES_Confidence_Interval": [0.469, 0.589], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.798, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.56212086659065, "ARES_Confidence_Interval": [0.503, 0.622], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.791, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.548284023668639, "ARES_Confidence_Interval": [0.488, 0.608], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.824, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.5271846846846847, "ARES_Confidence_Interval": [0.478, 0.576], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.873, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.5605383022774327, "ARES_Confidence_Interval": [0.511, 0.61], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.895, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5770879801734821, "ARES_Confidence_Interval": [0.527, 0.627], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.878, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.6041010689990282, "ARES_Confidence_Interval": [0.553, 0.655], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.6133333333333333, "ARES_Confidence_Interval": [0.562, 0.664], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.867, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.6360366068285814, "ARES_Confidence_Interval": [0.585, 0.687], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.86, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.6660805860805861, "ARES_Confidence_Interval": [0.614, 0.718], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.871, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.683458760927404, "ARES_Confidence_Interval": [0.631, 0.735], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.863, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.693214990138067, "ARES_Confidence_Interval": [0.641, 0.746], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.856, "Annotated_Examples_used_for_PPI": 300}]]