[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.45066666666666666, "ARES_Confidence_Interval": [0.392, 0.509], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.902, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.534}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.5118570474281897, "ARES_Confidence_Interval": [0.454, 0.57], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.595}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5018370073480294, "ARES_Confidence_Interval": [0.444, 0.56], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.922, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.585}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5158650634602538, "ARES_Confidence_Interval": [0.458, 0.574], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.904, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.599}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.5606666666666666, "ARES_Confidence_Interval": [0.504, 0.618], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.912, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.644}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.5639612558450233, "ARES_Confidence_Interval": [0.507, 0.621], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.926, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.647}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.5906666666666667, "ARES_Confidence_Interval": [0.534, 0.647], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.674}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.6100534402137608, "ARES_Confidence_Interval": [0.554, 0.666], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.914, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.693}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.6226666666666666, "ARES_Confidence_Interval": [0.567, 0.678], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.93, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.706}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.4926666666666667, "ARES_Confidence_Interval": [0.436, 0.549], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.526}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.5217768871075484, "ARES_Confidence_Interval": [0.465, 0.578], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.91, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.555}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5317969271877088, "ARES_Confidence_Interval": [0.476, 0.588], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.565}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5558450233800936, "ARES_Confidence_Interval": [0.5, 0.612], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.902, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.589}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.5846666666666667, "ARES_Confidence_Interval": [0.529, 0.64], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.914, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.618}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.5939211756847027, "ARES_Confidence_Interval": [0.539, 0.649], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.922, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.627}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.6406666666666667, "ARES_Confidence_Interval": [0.586, 0.695], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.674}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.6600534402137609, "ARES_Confidence_Interval": [0.606, 0.714], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.914, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.693}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.6446666666666667, "ARES_Confidence_Interval": [0.59, 0.699], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.906, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.678}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.44799999999999995, "ARES_Confidence_Interval": [0.381, 0.515], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.744, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.708}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.5576352705410822, "ARES_Confidence_Interval": [0.494, 0.621], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.671, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.818}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5055310621242485, "ARES_Confidence_Interval": [0.44, 0.571], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.745, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.766}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5155511022044088, "ARES_Confidence_Interval": [0.451, 0.581], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.739, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.776}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.502, "ARES_Confidence_Interval": [0.437, 0.567], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.794, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.762}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.5636472945891784, "ARES_Confidence_Interval": [0.5, 0.627], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.758, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.824}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.534, "ARES_Confidence_Interval": [0.47, 0.598], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.788, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.794}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.5295791583166333, "ARES_Confidence_Interval": [0.465, 0.594], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.822, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.79}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.5579999999999999, "ARES_Confidence_Interval": [0.494, 0.622], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.814, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.818}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_all.tsv", "ARES_Prediction": 0.5253333333333333, "ARES_Confidence_Interval": [0.466, 0.584], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.876, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.412}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_all.tsv", "ARES_Prediction": 0.5401870407481629, "ARES_Confidence_Interval": [0.481, 0.599], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.842, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.427}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_all.tsv", "ARES_Prediction": 0.5682431529726119, "ARES_Confidence_Interval": [0.509, 0.628], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.856, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.455}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_all.tsv", "ARES_Prediction": 0.5882832331329325, "ARES_Confidence_Interval": [0.529, 0.648], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.864, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.475}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_all.tsv", "ARES_Prediction": 0.6033333333333333, "ARES_Confidence_Interval": [0.544, 0.663], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.866, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.49}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_all.tsv", "ARES_Prediction": 0.6063193052772211, "ARES_Confidence_Interval": [0.547, 0.666], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.856, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.493}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_all.tsv", "ARES_Prediction": 0.6473333333333333, "ARES_Confidence_Interval": [0.588, 0.707], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.844, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.534}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_all.tsv", "ARES_Prediction": 0.6844756179024716, "ARES_Confidence_Interval": [0.625, 0.744], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.868, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.571}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_all.tsv", "ARES_Prediction": 0.6713333333333333, "ARES_Confidence_Interval": [0.612, 0.731], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.826, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.558}]]