[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.4672972972972972, "ARES_Confidence_Interval": [0.416, 0.518], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.895, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.48344276841171246, "ARES_Confidence_Interval": [0.432, 0.535], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.50364312267658, "ARES_Confidence_Interval": [0.452, 0.555], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.905, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5312730806608358, "ARES_Confidence_Interval": [0.479, 0.583], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.906, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5731440162271806, "ARES_Confidence_Interval": [0.521, 0.625], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.89, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.5620274551214361, "ARES_Confidence_Interval": [0.51, 0.614], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.907, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.587032967032967, "ARES_Confidence_Interval": [0.535, 0.639], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.909, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6007297605473204, "ARES_Confidence_Interval": [0.548, 0.653], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.914, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6324260355029586, "ARES_Confidence_Interval": [0.58, 0.685], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.912, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.4887612612612613, "ARES_Confidence_Interval": [0.444, 0.534], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.894, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5085743862762496, "ARES_Confidence_Interval": [0.463, 0.554], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.876, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.52636926889715, "ARES_Confidence_Interval": [0.481, 0.572], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.886, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5485034013605442, "ARES_Confidence_Interval": [0.503, 0.594], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.906, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5722853279242731, "ARES_Confidence_Interval": [0.526, 0.618], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.887, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.57229496656107, "ARES_Confidence_Interval": [0.526, 0.619], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.879, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.6028205128205129, "ARES_Confidence_Interval": [0.556, 0.649], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.899, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6225731660965412, "ARES_Confidence_Interval": [0.576, 0.669], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.879, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6513412228796844, "ARES_Confidence_Interval": [0.605, 0.698], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.899, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.48755630630630636, "ARES_Confidence_Interval": [0.428, 0.547], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.722, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.49375924282756584, "ARES_Confidence_Interval": [0.434, 0.553], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.74, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5270136307311029, "ARES_Confidence_Interval": [0.468, 0.586], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.734, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5205053449951409, "ARES_Confidence_Interval": [0.461, 0.58], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.775, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5457065584854632, "ARES_Confidence_Interval": [0.486, 0.605], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.77, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.551707145371348, "ARES_Confidence_Interval": [0.492, 0.611], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.784, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.5608058608058608, "ARES_Confidence_Interval": [0.501, 0.62], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.805, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.5862409730140632, "ARES_Confidence_Interval": [0.527, 0.645], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.806, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.5842209072978304, "ARES_Confidence_Interval": [0.525, 0.643], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.821, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.5189977477477478, "ARES_Confidence_Interval": [0.469, 0.569], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.861, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5435344572611653, "ARES_Confidence_Interval": [0.493, 0.594], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.862, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5600123915737298, "ARES_Confidence_Interval": [0.509, 0.611], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.851, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5842662779397474, "ARES_Confidence_Interval": [0.532, 0.636], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.852, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5988573360378635, "ARES_Confidence_Interval": [0.547, 0.651], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.842, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.6107321365716297, "ARES_Confidence_Interval": [0.558, 0.663], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.827, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.626996336996337, "ARES_Confidence_Interval": [0.574, 0.68], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.82, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6389927784112505, "ARES_Confidence_Interval": [0.585, 0.693], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.807, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6560749506903354, "ARES_Confidence_Interval": [0.602, 0.71], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.796, "Annotated_Examples_used_for_PPI": 300}]]