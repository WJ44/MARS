[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.436, "ARES_Confidence_Interval": [0.375, 0.497], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.516}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.4911422845691383, "ARES_Confidence_Interval": [0.43, 0.552], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.571}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5031663326653307, "ARES_Confidence_Interval": [0.443, 0.564], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.583}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5352304609218437, "ARES_Confidence_Interval": [0.475, 0.595], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.888, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.615}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.54, "ARES_Confidence_Interval": [0.48, 0.6], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.928, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.62}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.5672945891783567, "ARES_Confidence_Interval": [0.508, 0.627], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.886, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.647}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.5880000000000001, "ARES_Confidence_Interval": [0.529, 0.647], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.918, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.668}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6093787575150301, "ARES_Confidence_Interval": [0.551, 0.668], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.918, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.689}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.624, "ARES_Confidence_Interval": [0.566, 0.682], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.704}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.4926666666666667, "ARES_Confidence_Interval": [0.437, 0.549], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.536}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5037608550434202, "ARES_Confidence_Interval": [0.448, 0.56], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.874, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.547}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5238009352037408, "ARES_Confidence_Interval": [0.468, 0.58], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.567}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5398329993319974, "ARES_Confidence_Interval": [0.484, 0.595], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.583}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5686666666666667, "ARES_Confidence_Interval": [0.514, 0.624], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.888, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.612}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.5739011356045424, "ARES_Confidence_Interval": [0.519, 0.629], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.892, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.617}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.6306666666666667, "ARES_Confidence_Interval": [0.577, 0.685], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.674}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6340213760855044, "ARES_Confidence_Interval": [0.58, 0.688], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.677}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6166666666666667, "ARES_Confidence_Interval": [0.562, 0.671], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.66}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.4513333333333333, "ARES_Confidence_Interval": [0.384, 0.518], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.718}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5088844355377422, "ARES_Confidence_Interval": [0.444, 0.574], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.733, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.776}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5148964595858383, "ARES_Confidence_Interval": [0.45, 0.58], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.754, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.782}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5309285237140948, "ARES_Confidence_Interval": [0.466, 0.596], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.762, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.798}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5373333333333334, "ARES_Confidence_Interval": [0.473, 0.602], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.788, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.804}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.567000668002672, "ARES_Confidence_Interval": [0.504, 0.63], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.772, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.834}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.5713333333333332, "ARES_Confidence_Interval": [0.508, 0.634], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.796, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.838}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.567000668002672, "ARES_Confidence_Interval": [0.504, 0.63], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.838, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.834}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.5893333333333333, "ARES_Confidence_Interval": [0.527, 0.652], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.812, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.856}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.5106666666666666, "ARES_Confidence_Interval": [0.451, 0.57], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.854, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.354}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5133800935203741, "ARES_Confidence_Interval": [0.454, 0.573], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.832, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.357}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5554642618570474, "ARES_Confidence_Interval": [0.495, 0.616], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.848, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.399}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5694923179692719, "ARES_Confidence_Interval": [0.509, 0.63], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.838, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.413}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.5726666666666667, "ARES_Confidence_Interval": [0.512, 0.633], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.816, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.416}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.5955444221776887, "ARES_Confidence_Interval": [0.535, 0.656], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.814, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.439}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.6286666666666667, "ARES_Confidence_Interval": [0.568, 0.689], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.822, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.472}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6476486305945224, "ARES_Confidence_Interval": [0.587, 0.708], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.816, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.491}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6426666666666667, "ARES_Confidence_Interval": [0.582, 0.703], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.786, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.486}]]