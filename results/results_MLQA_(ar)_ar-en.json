[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_en.tsv", "ARES_Prediction": 0.49268018018018017, "ARES_Confidence_Interval": [0.443, 0.542], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_en.tsv", "ARES_Prediction": 0.5085034013605442, "ARES_Confidence_Interval": [0.459, 0.558], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.902, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_en.tsv", "ARES_Prediction": 0.5216852540272614, "ARES_Confidence_Interval": [0.472, 0.572], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.912, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_en.tsv", "ARES_Prediction": 0.5561224489795918, "ARES_Confidence_Interval": [0.506, 0.606], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.907, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_en.tsv", "ARES_Prediction": 0.5829952670723462, "ARES_Confidence_Interval": [0.533, 0.633], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.906, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_en.tsv", "ARES_Prediction": 0.590373108060542, "ARES_Confidence_Interval": [0.54, 0.641], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.909, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_en.tsv", "ARES_Prediction": 0.6210622710622711, "ARES_Confidence_Interval": [0.571, 0.671], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.902, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_en.tsv", "ARES_Prediction": 0.6247624477385024, "ARES_Confidence_Interval": [0.574, 0.675], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.921, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_en.tsv", "ARES_Prediction": 0.651577909270217, "ARES_Confidence_Interval": [0.601, 0.702], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.909, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_en.tsv", "ARES_Prediction": 0.5236486486486487, "ARES_Confidence_Interval": [0.483, 0.564], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.939, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_en.tsv", "ARES_Prediction": 0.5581188997338066, "ARES_Confidence_Interval": [0.517, 0.599], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_en.tsv", "ARES_Prediction": 0.5762081784386617, "ARES_Confidence_Interval": [0.535, 0.618], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.931, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_en.tsv", "ARES_Prediction": 0.586977648202138, "ARES_Confidence_Interval": [0.545, 0.629], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.936, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_en.tsv", "ARES_Prediction": 0.6166328600405679, "ARES_Confidence_Interval": [0.575, 0.659], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.945, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_en.tsv", "ARES_Prediction": 0.6473072861668426, "ARES_Confidence_Interval": [0.605, 0.689], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.946, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_en.tsv", "ARES_Prediction": 0.6637362637362637, "ARES_Confidence_Interval": [0.621, 0.706], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.927, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_en.tsv", "ARES_Prediction": 0.6681870011402509, "ARES_Confidence_Interval": [0.625, 0.711], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.936, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_en.tsv", "ARES_Prediction": 0.714792899408284, "ARES_Confidence_Interval": [0.673, 0.757], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.938, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_en.tsv", "ARES_Prediction": 0.464268018018018, "ARES_Confidence_Interval": [0.404, 0.525], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.714, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_en.tsv", "ARES_Prediction": 0.480402247855664, "ARES_Confidence_Interval": [0.42, 0.541], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.709, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_en.tsv", "ARES_Prediction": 0.48733581164807926, "ARES_Confidence_Interval": [0.427, 0.548], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.73, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_en.tsv", "ARES_Prediction": 0.496754130223518, "ARES_Confidence_Interval": [0.436, 0.558], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.754, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_en.tsv", "ARES_Prediction": 0.5038269100743745, "ARES_Confidence_Interval": [0.443, 0.565], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.763, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_en.tsv", "ARES_Prediction": 0.513424850404787, "ARES_Confidence_Interval": [0.452, 0.574], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.787, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_en.tsv", "ARES_Prediction": 0.520952380952381, "ARES_Confidence_Interval": [0.46, 0.582], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.803, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_en.tsv", "ARES_Prediction": 0.5470315469403269, "ARES_Confidence_Interval": [0.486, 0.608], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.789, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_en.tsv", "ARES_Prediction": 0.5528205128205128, "ARES_Confidence_Interval": [0.492, 0.613], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.8, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_en.tsv", "ARES_Prediction": 0.4945382882882883, "ARES_Confidence_Interval": [0.454, 0.535], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.938, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_en.tsv", "ARES_Prediction": 0.5309967465246969, "ARES_Confidence_Interval": [0.49, 0.572], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.94, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_en.tsv", "ARES_Prediction": 0.5345105328376704, "ARES_Confidence_Interval": [0.493, 0.576], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.954, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_en.tsv", "ARES_Prediction": 0.5643343051506317, "ARES_Confidence_Interval": [0.523, 0.606], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.945, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_en.tsv", "ARES_Prediction": 0.5964841108857336, "ARES_Confidence_Interval": [0.555, 0.638], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.95, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_en.tsv", "ARES_Prediction": 0.5970784934882084, "ARES_Confidence_Interval": [0.555, 0.639], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.938, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_en.tsv", "ARES_Prediction": 0.6293040293040293, "ARES_Confidence_Interval": [0.587, 0.672], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.935, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_en.tsv", "ARES_Prediction": 0.6587989357658685, "ARES_Confidence_Interval": [0.617, 0.701], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.949, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_en.tsv", "ARES_Prediction": 0.6755424063116371, "ARES_Confidence_Interval": [0.633, 0.718], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.956, "Annotated_Examples_used_for_PPI": 300}]]