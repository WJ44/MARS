[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_en.tsv", "ARES_Prediction": 0.504009009009009, "ARES_Confidence_Interval": [0.463, 0.545], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.936, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_en.tsv", "ARES_Prediction": 0.5185507246376811, "ARES_Confidence_Interval": [0.477, 0.56], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.941, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_en.tsv", "ARES_Prediction": 0.5453407682775713, "ARES_Confidence_Interval": [0.503, 0.587], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.932, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_en.tsv", "ARES_Prediction": 0.5578036929057337, "ARES_Confidence_Interval": [0.515, 0.6], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.957, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_en.tsv", "ARES_Prediction": 0.602420554428668, "ARES_Confidence_Interval": [0.56, 0.645], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.937, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_en.tsv", "ARES_Prediction": 0.6196480112636396, "ARES_Confidence_Interval": [0.577, 0.662], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.942, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_en.tsv", "ARES_Prediction": 0.6456410256410257, "ARES_Confidence_Interval": [0.603, 0.688], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.941, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_en.tsv", "ARES_Prediction": 0.6454656024325351, "ARES_Confidence_Interval": [0.603, 0.688], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.946, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_en.tsv", "ARES_Prediction": 0.6681262327416174, "ARES_Confidence_Interval": [0.625, 0.711], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.95, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_en.tsv", "ARES_Prediction": 0.5203153153153154, "ARES_Confidence_Interval": [0.48, 0.561], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.939, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_en.tsv", "ARES_Prediction": 0.5547855664004733, "ARES_Confidence_Interval": [0.514, 0.595], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_en.tsv", "ARES_Prediction": 0.5728748451053284, "ARES_Confidence_Interval": [0.532, 0.614], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.931, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_en.tsv", "ARES_Prediction": 0.5836443148688047, "ARES_Confidence_Interval": [0.542, 0.625], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.936, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_en.tsv", "ARES_Prediction": 0.6132995267072346, "ARES_Confidence_Interval": [0.572, 0.655], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.945, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_en.tsv", "ARES_Prediction": 0.6439739528335093, "ARES_Confidence_Interval": [0.602, 0.686], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.946, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_en.tsv", "ARES_Prediction": 0.6604029304029304, "ARES_Confidence_Interval": [0.619, 0.702], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.927, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_en.tsv", "ARES_Prediction": 0.6648536678069176, "ARES_Confidence_Interval": [0.623, 0.707], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.936, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_en.tsv", "ARES_Prediction": 0.7114595660749508, "ARES_Confidence_Interval": [0.67, 0.753], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.938, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_en.tsv", "ARES_Prediction": 0.5219144144144143, "ARES_Confidence_Interval": [0.467, 0.577], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.726, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_en.tsv", "ARES_Prediction": 0.5270689145223306, "ARES_Confidence_Interval": [0.472, 0.582], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.743, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_en.tsv", "ARES_Prediction": 0.5256381660470879, "ARES_Confidence_Interval": [0.47, 0.581], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.765, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_en.tsv", "ARES_Prediction": 0.55022351797862, "ARES_Confidence_Interval": [0.495, 0.606], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.771, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_en.tsv", "ARES_Prediction": 0.5717917511832319, "ARES_Confidence_Interval": [0.517, 0.627], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.772, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_en.tsv", "ARES_Prediction": 0.5875466385075677, "ARES_Confidence_Interval": [0.533, 0.643], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.787, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_en.tsv", "ARES_Prediction": 0.5994871794871794, "ARES_Confidence_Interval": [0.545, 0.654], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.791, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_en.tsv", "ARES_Prediction": 0.5879969593310528, "ARES_Confidence_Interval": [0.533, 0.643], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.829, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_en.tsv", "ARES_Prediction": 0.6030374753451676, "ARES_Confidence_Interval": [0.548, 0.658], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.832, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_en.tsv", "ARES_Prediction": 0.48498873873873877, "ARES_Confidence_Interval": [0.434, 0.536], "Number_of_Examples_in_Evaluation_Set": 1184, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.802, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_en.tsv", "ARES_Prediction": 0.5229340431824904, "ARES_Confidence_Interval": [0.471, 0.575], "Number_of_Examples_in_Evaluation_Set": 1127, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.81, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_en.tsv", "ARES_Prediction": 0.5357868649318464, "ARES_Confidence_Interval": [0.483, 0.588], "Number_of_Examples_in_Evaluation_Set": 1076, "Ground_Truth_Performance": 0.55, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.807, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_en.tsv", "ARES_Prediction": 0.567891156462585, "ARES_Confidence_Interval": [0.515, 0.621], "Number_of_Examples_in_Evaluation_Set": 1029, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.808, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_en.tsv", "ARES_Prediction": 0.553657876943881, "ARES_Confidence_Interval": [0.5, 0.607], "Number_of_Examples_in_Evaluation_Set": 986, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.772, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_en.tsv", "ARES_Prediction": 0.5904399859204505, "ARES_Confidence_Interval": [0.537, 0.644], "Number_of_Examples_in_Evaluation_Set": 947, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.767, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_en.tsv", "ARES_Prediction": 0.603003663003663, "ARES_Confidence_Interval": [0.549, 0.657], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.773, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_en.tsv", "ARES_Prediction": 0.6123299125807677, "ARES_Confidence_Interval": [0.558, 0.667], "Number_of_Examples_in_Evaluation_Set": 877, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.755, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_en.tsv", "ARES_Prediction": 0.6384220907297831, "ARES_Confidence_Interval": [0.583, 0.694], "Number_of_Examples_in_Evaluation_Set": 845, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.76, "Annotated_Examples_used_for_PPI": 300}]]