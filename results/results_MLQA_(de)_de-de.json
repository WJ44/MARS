[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_de.tsv", "ARES_Prediction": 0.5212774451097804, "ARES_Confidence_Interval": [0.475, 0.568], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.894, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_de.tsv", "ARES_Prediction": 0.5247798742138364, "ARES_Confidence_Interval": [0.478, 0.572], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.904, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_de.tsv", "ARES_Prediction": 0.5482783882783883, "ARES_Confidence_Interval": [0.501, 0.596], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.91, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_de.tsv", "ARES_Prediction": 0.5673861461921162, "ARES_Confidence_Interval": [0.52, 0.615], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_de.tsv", "ARES_Prediction": 0.5801596806387225, "ARES_Confidence_Interval": [0.532, 0.628], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.917, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_de.tsv", "ARES_Prediction": 0.5863420724094881, "ARES_Confidence_Interval": [0.538, 0.635], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_de.tsv", "ARES_Prediction": 0.6335930735930736, "ARES_Confidence_Interval": [0.585, 0.682], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.914, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_de.tsv", "ARES_Prediction": 0.6483198562443845, "ARES_Confidence_Interval": [0.6, 0.697], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.915, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_de.tsv", "ARES_Prediction": 0.6646620046620046, "ARES_Confidence_Interval": [0.616, 0.713], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.917, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_de.tsv", "ARES_Prediction": 0.5202994011976048, "ARES_Confidence_Interval": [0.479, 0.561], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_de.tsv", "ARES_Prediction": 0.5578406708595387, "ARES_Confidence_Interval": [0.516, 0.599], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.912, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_de.tsv", "ARES_Prediction": 0.5725641025641025, "ARES_Confidence_Interval": [0.531, 0.615], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.915, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_de.tsv", "ARES_Prediction": 0.5934596249521622, "ARES_Confidence_Interval": [0.551, 0.636], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_de.tsv", "ARES_Prediction": 0.6332734530938123, "ARES_Confidence_Interval": [0.591, 0.676], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_de.tsv", "ARES_Prediction": 0.6337952559300873, "ARES_Confidence_Interval": [0.591, 0.677], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_de.tsv", "ARES_Prediction": 0.6643722943722944, "ARES_Confidence_Interval": [0.621, 0.707], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.922, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_de.tsv", "ARES_Prediction": 0.661015274034142, "ARES_Confidence_Interval": [0.618, 0.705], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.937, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_de.tsv", "ARES_Prediction": 0.6816550116550116, "ARES_Confidence_Interval": [0.638, 0.725], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.919, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_de.tsv", "ARES_Prediction": 0.48752495009980035, "ARES_Confidence_Interval": [0.429, 0.546], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.745, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_de.tsv", "ARES_Prediction": 0.48899371069182385, "ARES_Confidence_Interval": [0.43, 0.548], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.757, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_de.tsv", "ARES_Prediction": 0.5170329670329671, "ARES_Confidence_Interval": [0.459, 0.575], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.755, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_de.tsv", "ARES_Prediction": 0.5353042479908151, "ARES_Confidence_Interval": [0.477, 0.594], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.76, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_de.tsv", "ARES_Prediction": 0.5344311377245509, "ARES_Confidence_Interval": [0.476, 0.593], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.799, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_de.tsv", "ARES_Prediction": 0.5327715355805244, "ARES_Confidence_Interval": [0.474, 0.592], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.808, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_de.tsv", "ARES_Prediction": 0.5396103896103897, "ARES_Confidence_Interval": [0.481, 0.599], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.848, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_de.tsv", "ARES_Prediction": 0.5774932614555256, "ARES_Confidence_Interval": [0.519, 0.636], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.821, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_de.tsv", "ARES_Prediction": 0.5835664335664336, "ARES_Confidence_Interval": [0.525, 0.642], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.85, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_de.tsv", "ARES_Prediction": 0.5229740518962076, "ARES_Confidence_Interval": [0.468, 0.578], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.802, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_de.tsv", "ARES_Prediction": 0.5424947589098532, "ARES_Confidence_Interval": [0.487, 0.598], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.803, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_de.tsv", "ARES_Prediction": 0.5733699633699634, "ARES_Confidence_Interval": [0.517, 0.629], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.807, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_de.tsv", "ARES_Prediction": 0.5624301569077689, "ARES_Confidence_Interval": [0.506, 0.619], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.788, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_de.tsv", "ARES_Prediction": 0.5802594810379241, "ARES_Confidence_Interval": [0.523, 0.637], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.775, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_de.tsv", "ARES_Prediction": 0.6011360799001249, "ARES_Confidence_Interval": [0.544, 0.658], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.777, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_de.tsv", "ARES_Prediction": 0.5948484848484848, "ARES_Confidence_Interval": [0.537, 0.653], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.747, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_de.tsv", "ARES_Prediction": 0.6402785265049415, "ARES_Confidence_Interval": [0.582, 0.699], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.767, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_de.tsv", "ARES_Prediction": 0.6298135198135199, "ARES_Confidence_Interval": [0.571, 0.689], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.722, "Annotated_Examples_used_for_PPI": 300}]]