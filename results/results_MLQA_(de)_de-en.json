[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.4932734530938123, "ARES_Confidence_Interval": [0.445, 0.542], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.5167924528301887, "ARES_Confidence_Interval": [0.468, 0.566], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.907, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5292673992673993, "ARES_Confidence_Interval": [0.48, 0.579], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.5500153080750096, "ARES_Confidence_Interval": [0.5, 0.6], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.906, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5633333333333334, "ARES_Confidence_Interval": [0.513, 0.613], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.5788139825218477, "ARES_Confidence_Interval": [0.529, 0.629], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.89, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.5970995670995671, "ARES_Confidence_Interval": [0.547, 0.648], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.923, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.6277538185085355, "ARES_Confidence_Interval": [0.577, 0.678], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.927, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.6458508158508159, "ARES_Confidence_Interval": [0.595, 0.696], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.909, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.5155888223552895, "ARES_Confidence_Interval": [0.474, 0.558], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.923, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.5144025157232704, "ARES_Confidence_Interval": [0.472, 0.557], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.929, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5447985347985348, "ARES_Confidence_Interval": [0.502, 0.588], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.919, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.5886069651741294, "ARES_Confidence_Interval": [0.546, 0.632], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.933, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5994211576846308, "ARES_Confidence_Interval": [0.556, 0.643], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.932, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.6196129837702872, "ARES_Confidence_Interval": [0.576, 0.663], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.935, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.6467965367965368, "ARES_Confidence_Interval": [0.603, 0.69], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.929, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.6518688230008984, "ARES_Confidence_Interval": [0.608, 0.696], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.949, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.6703729603729603, "ARES_Confidence_Interval": [0.626, 0.714], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.931, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.546187624750499, "ARES_Confidence_Interval": [0.486, 0.606], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.731, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.5351781970649895, "ARES_Confidence_Interval": [0.475, 0.596], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.742, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5495238095238095, "ARES_Confidence_Interval": [0.489, 0.61], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.751, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.5816379640260237, "ARES_Confidence_Interval": [0.521, 0.642], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.752, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5803193612774451, "ARES_Confidence_Interval": [0.52, 0.641], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.781, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.5856928838951311, "ARES_Confidence_Interval": [0.525, 0.646], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.774, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.581991341991342, "ARES_Confidence_Interval": [0.521, 0.643], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.821, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.5923809523809523, "ARES_Confidence_Interval": [0.531, 0.653], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.822, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.6374358974358975, "ARES_Confidence_Interval": [0.577, 0.697], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.811, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_de_en.tsv", "ARES_Prediction": 0.5454491017964072, "ARES_Confidence_Interval": [0.49, 0.601], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.818, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_de_en.tsv", "ARES_Prediction": 0.5561635220125787, "ARES_Confidence_Interval": [0.5, 0.612], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.823, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_de_en.tsv", "ARES_Prediction": 0.5747619047619048, "ARES_Confidence_Interval": [0.518, 0.631], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.831, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_de_en.tsv", "ARES_Prediction": 0.5832414848832759, "ARES_Confidence_Interval": [0.526, 0.64], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.817, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_de_en.tsv", "ARES_Prediction": 0.5883632734530938, "ARES_Confidence_Interval": [0.531, 0.646], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.813, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_de_en.tsv", "ARES_Prediction": 0.6289263420724094, "ARES_Confidence_Interval": [0.571, 0.687], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.815, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_de_en.tsv", "ARES_Prediction": 0.6370995670995672, "ARES_Confidence_Interval": [0.579, 0.695], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.795, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_de_en.tsv", "ARES_Prediction": 0.6868912848158131, "ARES_Confidence_Interval": [0.629, 0.745], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.814, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_de_en.tsv", "ARES_Prediction": 0.6837529137529137, "ARES_Confidence_Interval": [0.625, 0.742], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.79, "Annotated_Examples_used_for_PPI": 300}]]