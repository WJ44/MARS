[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.4739321357285429, "ARES_Confidence_Interval": [0.425, 0.523], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.92, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5091823899371068, "ARES_Confidence_Interval": [0.46, 0.558], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.91, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.5378021978021978, "ARES_Confidence_Interval": [0.489, 0.587], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.937, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.5439035591274397, "ARES_Confidence_Interval": [0.494, 0.594], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.93, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.5831137724550899, "ARES_Confidence_Interval": [0.534, 0.633], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.938, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.5941822721598002, "ARES_Confidence_Interval": [0.544, 0.644], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.921, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.6023376623376624, "ARES_Confidence_Interval": [0.552, 0.653], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.939, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.6381132075471698, "ARES_Confidence_Interval": [0.588, 0.688], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.939, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.6448951048951048, "ARES_Confidence_Interval": [0.595, 0.695], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.94, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.5002994011976047, "ARES_Confidence_Interval": [0.454, 0.546], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5378406708595387, "ARES_Confidence_Interval": [0.492, 0.584], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.912, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.5525641025641025, "ARES_Confidence_Interval": [0.506, 0.599], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.915, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.5734596249521622, "ARES_Confidence_Interval": [0.526, 0.621], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.6132734530938123, "ARES_Confidence_Interval": [0.566, 0.66], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.6137952559300873, "ARES_Confidence_Interval": [0.566, 0.661], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.925, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.6443722943722944, "ARES_Confidence_Interval": [0.597, 0.692], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.922, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.6410152740341419, "ARES_Confidence_Interval": [0.593, 0.689], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.937, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.6616550116550116, "ARES_Confidence_Interval": [0.613, 0.71], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.919, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.527185628742515, "ARES_Confidence_Interval": [0.468, 0.586], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.71, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5350943396226414, "ARES_Confidence_Interval": [0.476, 0.594], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.737, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.5427106227106226, "ARES_Confidence_Interval": [0.483, 0.602], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.764, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.5455644852659778, "ARES_Confidence_Interval": [0.486, 0.605], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.78, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.5663073852295408, "ARES_Confidence_Interval": [0.507, 0.626], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.784, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.5806741573033708, "ARES_Confidence_Interval": [0.521, 0.64], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.782, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.6165367965367965, "ARES_Confidence_Interval": [0.558, 0.675], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.784, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.6262893081761006, "ARES_Confidence_Interval": [0.568, 0.685], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.806, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.6328205128205128, "ARES_Confidence_Interval": [0.574, 0.692], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.813, "Annotated_Examples_used_for_PPI": 300}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.5035728542914172, "ARES_Confidence_Interval": [0.445, 0.563], "Number_of_Examples_in_Evaluation_Set": 1002, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.79, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5321383647798742, "ARES_Confidence_Interval": [0.473, 0.592], "Number_of_Examples_in_Evaluation_Set": 954, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.791, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.5727838827838828, "ARES_Confidence_Interval": [0.513, 0.633], "Number_of_Examples_in_Evaluation_Set": 910, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.811, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.5515767317259854, "ARES_Confidence_Interval": [0.491, 0.612], "Number_of_Examples_in_Evaluation_Set": 871, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.791, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.5496806387225549, "ARES_Confidence_Interval": [0.489, 0.611], "Number_of_Examples_in_Evaluation_Set": 835, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.762, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.6027340823970038, "ARES_Confidence_Interval": [0.541, 0.664], "Number_of_Examples_in_Evaluation_Set": 801, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.782, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.5843722943722943, "ARES_Confidence_Interval": [0.523, 0.646], "Number_of_Examples_in_Evaluation_Set": 770, "Ground_Truth_Performance": 0.651, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.771, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.6152470799640611, "ARES_Confidence_Interval": [0.553, 0.677], "Number_of_Examples_in_Evaluation_Set": 742, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.771, "Annotated_Examples_used_for_PPI": 300}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.6198368298368299, "ARES_Confidence_Interval": [0.557, 0.682], "Number_of_Examples_in_Evaluation_Set": 715, "Ground_Truth_Performance": 0.701, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.74, "Annotated_Examples_used_for_PPI": 300}]]