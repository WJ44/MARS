[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.486, "ARES_Confidence_Interval": [0.431, 0.541], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.516}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5411422845691383, "ARES_Confidence_Interval": [0.487, 0.595], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.571}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5531663326653307, "ARES_Confidence_Interval": [0.499, 0.607], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.583}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.5852304609218436, "ARES_Confidence_Interval": [0.532, 0.639], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.888, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.615}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.59, "ARES_Confidence_Interval": [0.536, 0.644], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.928, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.62}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.6172945891783567, "ARES_Confidence_Interval": [0.564, 0.67], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.886, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.647}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.638, "ARES_Confidence_Interval": [0.585, 0.691], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.918, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.668}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6593787575150301, "ARES_Confidence_Interval": [0.607, 0.711], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.918, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.689}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6739999999999999, "ARES_Confidence_Interval": [0.622, 0.726], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.704}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.5493333333333333, "ARES_Confidence_Interval": [0.492, 0.607], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.536}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5604275217100868, "ARES_Confidence_Interval": [0.503, 0.618], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.874, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.547}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5804676018704075, "ARES_Confidence_Interval": [0.523, 0.638], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.567}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.596499665998664, "ARES_Confidence_Interval": [0.54, 0.653], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.583}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.6253333333333333, "ARES_Confidence_Interval": [0.569, 0.682], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.888, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.612}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.630567802271209, "ARES_Confidence_Interval": [0.574, 0.687], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.892, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.617}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.6873333333333334, "ARES_Confidence_Interval": [0.632, 0.743], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.674}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.690688042752171, "ARES_Confidence_Interval": [0.635, 0.746], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.677}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6733333333333333, "ARES_Confidence_Interval": [0.618, 0.729], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.66}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.578, "ARES_Confidence_Interval": [0.519, 0.637], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.746, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.718}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.6355511022044088, "ARES_Confidence_Interval": [0.578, 0.693], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.733, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.776}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.641563126252505, "ARES_Confidence_Interval": [0.584, 0.699], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.754, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.782}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.6575951903807615, "ARES_Confidence_Interval": [0.601, 0.714], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.762, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.798}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.664, "ARES_Confidence_Interval": [0.608, 0.72], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.788, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.804}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.6936673346693386, "ARES_Confidence_Interval": [0.639, 0.749], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.772, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.834}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.698, "ARES_Confidence_Interval": [0.643, 0.753], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.796, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.838}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6936673346693386, "ARES_Confidence_Interval": [0.639, 0.749], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.838, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.834}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.716, "ARES_Confidence_Interval": [0.662, 0.77], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.812, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.856}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_ar_ar.tsv", "ARES_Prediction": 0.554, "ARES_Confidence_Interval": [0.492, 0.616], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.854, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.354}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_ar_ar.tsv", "ARES_Prediction": 0.5567134268537075, "ARES_Confidence_Interval": [0.495, 0.618], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.832, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.357}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_ar_ar.tsv", "ARES_Prediction": 0.5987975951903808, "ARES_Confidence_Interval": [0.536, 0.661], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.848, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.399}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_ar_ar.tsv", "ARES_Prediction": 0.6128256513026052, "ARES_Confidence_Interval": [0.55, 0.675], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.838, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.413}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_ar_ar.tsv", "ARES_Prediction": 0.616, "ARES_Confidence_Interval": [0.553, 0.679], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.816, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.416}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_ar_ar.tsv", "ARES_Prediction": 0.6388777555110221, "ARES_Confidence_Interval": [0.576, 0.702], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.814, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.439}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_ar_ar.tsv", "ARES_Prediction": 0.6719999999999999, "ARES_Confidence_Interval": [0.609, 0.735], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.822, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.472}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_ar_ar.tsv", "ARES_Prediction": 0.6909819639278557, "ARES_Confidence_Interval": [0.628, 0.754], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.816, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.491}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_ar_ar.tsv", "ARES_Prediction": 0.6859999999999999, "ARES_Confidence_Interval": [0.623, 0.749], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.786, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.486}]]