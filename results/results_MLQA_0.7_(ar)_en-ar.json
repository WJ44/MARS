[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_ar.tsv", "ARES_Prediction": 0.536, "ARES_Confidence_Interval": [0.477, 0.595], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.516}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_ar.tsv", "ARES_Prediction": 0.5570741482965932, "ARES_Confidence_Interval": [0.498, 0.616], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.888, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.537}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_ar.tsv", "ARES_Prediction": 0.5991583166332666, "ARES_Confidence_Interval": [0.541, 0.658], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.579}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_ar.tsv", "ARES_Prediction": 0.613186372745491, "ARES_Confidence_Interval": [0.555, 0.671], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.874, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.593}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_ar.tsv", "ARES_Prediction": 0.618, "ARES_Confidence_Interval": [0.56, 0.676], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.894, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.598}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_ar.tsv", "ARES_Prediction": 0.6512625250501002, "ARES_Confidence_Interval": [0.594, 0.709], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.878, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.631}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_ar.tsv", "ARES_Prediction": 0.674, "ARES_Confidence_Interval": [0.617, 0.731], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.654}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_ar.tsv", "ARES_Prediction": 0.6813226452905812, "ARES_Confidence_Interval": [0.624, 0.738], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.661}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_ar.tsv", "ARES_Prediction": 0.718, "ARES_Confidence_Interval": [0.662, 0.774], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.886, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.698}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_ar.tsv", "ARES_Prediction": 0.526, "ARES_Confidence_Interval": [0.468, 0.584], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.536}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_ar.tsv", "ARES_Prediction": 0.5370941883767535, "ARES_Confidence_Interval": [0.479, 0.595], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.874, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.547}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_ar.tsv", "ARES_Prediction": 0.5571342685370742, "ARES_Confidence_Interval": [0.499, 0.615], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.567}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_ar.tsv", "ARES_Prediction": 0.5731663326653307, "ARES_Confidence_Interval": [0.515, 0.631], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.88, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.583}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_ar.tsv", "ARES_Prediction": 0.602, "ARES_Confidence_Interval": [0.544, 0.66], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.888, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.612}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_ar.tsv", "ARES_Prediction": 0.6072344689378757, "ARES_Confidence_Interval": [0.55, 0.665], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.892, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.617}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_ar.tsv", "ARES_Prediction": 0.664, "ARES_Confidence_Interval": [0.608, 0.72], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.674}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_ar.tsv", "ARES_Prediction": 0.6673547094188377, "ARES_Confidence_Interval": [0.611, 0.724], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.898, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.677}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_ar.tsv", "ARES_Prediction": 0.65, "ARES_Confidence_Interval": [0.593, 0.707], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.884, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.66}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_ar.tsv", "ARES_Prediction": 0.6446666666666667, "ARES_Confidence_Interval": [0.573, 0.716], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.684, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.668}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_ar.tsv", "ARES_Prediction": 0.6359853039412158, "ARES_Confidence_Interval": [0.564, 0.708], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.725, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.659}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_ar.tsv", "ARES_Prediction": 0.674061456245825, "ARES_Confidence_Interval": [0.603, 0.745], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.729, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.697}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_ar.tsv", "ARES_Prediction": 0.6460053440213761, "ARES_Confidence_Interval": [0.574, 0.718], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.697, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.669}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_ar.tsv", "ARES_Prediction": 0.6826666666666666, "ARES_Confidence_Interval": [0.612, 0.754], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.742, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.706}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_ar.tsv", "ARES_Prediction": 0.7001135604542418, "ARES_Confidence_Interval": [0.629, 0.771], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.725, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.723}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_ar.tsv", "ARES_Prediction": 0.6906666666666667, "ARES_Confidence_Interval": [0.62, 0.762], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.764, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.714}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_ar.tsv", "ARES_Prediction": 0.6920975283901136, "ARES_Confidence_Interval": [0.621, 0.763], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.723, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.715}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_ar.tsv", "ARES_Prediction": 0.7206666666666667, "ARES_Confidence_Interval": [0.651, 0.791], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.78, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.744}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.5_en_ar.tsv", "ARES_Prediction": 0.5266666666666667, "ARES_Confidence_Interval": [0.474, 0.579], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.46}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.525_en_ar.tsv", "ARES_Prediction": 0.5336005344021376, "ARES_Confidence_Interval": [0.481, 0.586], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.906, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.467}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.55_en_ar.tsv", "ARES_Prediction": 0.5636606546426186, "ARES_Confidence_Interval": [0.511, 0.617], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.918, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.497}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.575_en_ar.tsv", "ARES_Prediction": 0.5877087508350033, "ARES_Confidence_Interval": [0.535, 0.641], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.922, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.521}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.6_en_ar.tsv", "ARES_Prediction": 0.5906666666666667, "ARES_Confidence_Interval": [0.538, 0.644], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.904, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.524}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.625_en_ar.tsv", "ARES_Prediction": 0.639812959251837, "ARES_Confidence_Interval": [0.587, 0.692], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.936, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.573}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.65_en_ar.tsv", "ARES_Prediction": 0.6386666666666666, "ARES_Confidence_Interval": [0.586, 0.691], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.894, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.572}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.675_en_ar.tsv", "ARES_Prediction": 0.6778891115564462, "ARES_Confidence_Interval": [0.626, 0.73], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.904, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.611}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(ar)_test_ratio_0.7_en_ar.tsv", "ARES_Prediction": 0.7006666666666667, "ARES_Confidence_Interval": [0.649, 0.752], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.91, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.634}]]