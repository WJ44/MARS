[[{"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.524, "ARES_Confidence_Interval": [0.466, 0.582], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.908, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.544}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5551503006012024, "ARES_Confidence_Interval": [0.497, 0.613], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.926, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.575}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.5751903807615231, "ARES_Confidence_Interval": [0.518, 0.633], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.932, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.595}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.5892184368737475, "ARES_Confidence_Interval": [0.532, 0.646], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.934, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.609}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.602, "ARES_Confidence_Interval": [0.545, 0.659], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.926, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.622}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.6092585170340681, "ARES_Confidence_Interval": [0.552, 0.666], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.932, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.629}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.656, "ARES_Confidence_Interval": [0.6, 0.712], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.934, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.676}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.6773947895791583, "ARES_Confidence_Interval": [0.622, 0.733], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.942, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.697}, {"Label_Column": "Context_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.6779999999999999, "ARES_Confidence_Interval": [0.623, 0.733], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.954, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.698}], [{"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.5433333333333333, "ARES_Confidence_Interval": [0.488, 0.599], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.928, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.52}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5884635938543754, "ARES_Confidence_Interval": [0.533, 0.644], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.916, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.565}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.5784435537742151, "ARES_Confidence_Interval": [0.523, 0.634], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.928, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.555}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.6305477621910488, "ARES_Confidence_Interval": [0.576, 0.685], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.904, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.607}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.6113333333333333, "ARES_Confidence_Interval": [0.556, 0.666], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.588}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.640567802271209, "ARES_Confidence_Interval": [0.586, 0.695], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.9, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.617}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.6653333333333333, "ARES_Confidence_Interval": [0.611, 0.719], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.912, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.642}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.7167201068804275, "ARES_Confidence_Interval": [0.664, 0.769], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.938, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.693}, {"Label_Column": "Answer_Relevance_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.7353333333333333, "ARES_Confidence_Interval": [0.683, 0.787], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.92, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.712}], [{"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.6326666666666667, "ARES_Confidence_Interval": [0.573, 0.692], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.696, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.756}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.6502137608550435, "ARES_Confidence_Interval": [0.591, 0.709], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.723, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.774}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.6442017368069473, "ARES_Confidence_Interval": [0.585, 0.704], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.747, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.768}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.6802738810955244, "ARES_Confidence_Interval": [0.622, 0.738], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.739, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.804}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.6586666666666667, "ARES_Confidence_Interval": [0.6, 0.718], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.782, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.782}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.668249832999332, "ARES_Confidence_Interval": [0.61, 0.727], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.778, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.792}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.6846666666666668, "ARES_Confidence_Interval": [0.627, 0.742], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.798, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.808}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.696305945223781, "ARES_Confidence_Interval": [0.639, 0.754], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.812, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.82}, {"Label_Column": "Answer_Faithfulness_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.6846666666666668, "ARES_Confidence_Interval": [0.627, 0.742], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.844, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.808}], [{"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.5_en_de.tsv", "ARES_Prediction": 0.5680000000000001, "ARES_Confidence_Interval": [0.504, 0.632], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.5, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.808, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.388}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.525_en_de.tsv", "ARES_Prediction": 0.5888176352705411, "ARES_Confidence_Interval": [0.524, 0.653], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.525, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.804, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.409}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.55_en_de.tsv", "ARES_Prediction": 0.6188777555110221, "ARES_Confidence_Interval": [0.554, 0.684], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.551, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.764, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.439}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.575_en_de.tsv", "ARES_Prediction": 0.6248897795591182, "ARES_Confidence_Interval": [0.56, 0.69], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.575, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.79, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.445}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.6_en_de.tsv", "ARES_Prediction": 0.648, "ARES_Confidence_Interval": [0.583, 0.713], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.6, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.816, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.468}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.625_en_de.tsv", "ARES_Prediction": 0.6288977955911823, "ARES_Confidence_Interval": [0.564, 0.694], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.625, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.76, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.449}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.65_en_de.tsv", "ARES_Prediction": 0.6539999999999999, "ARES_Confidence_Interval": [0.589, 0.719], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.65, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.768, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.474}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.675_en_de.tsv", "ARES_Prediction": 0.681002004008016, "ARES_Confidence_Interval": [0.616, 0.746], "Number_of_Examples_in_Evaluation_Set": 499, "Ground_Truth_Performance": 0.675, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.794, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.501}, {"Label_Column": "Language_Consistency_Label", "Evaluation_Set": "multilingual_data/mlqa_(de)_test_ratio_0.7_en_de.tsv", "ARES_Prediction": 0.7, "ARES_Confidence_Interval": [0.635, 0.765], "Number_of_Examples_in_Evaluation_Set": 500, "Ground_Truth_Performance": 0.7, "ARES_LLM_Judge_Accuracy_on_Ground_Truth_Labels": 0.744, "Annotated_Examples_used_for_PPI": 300, "Pre_PPI_Score": 0.52}]]